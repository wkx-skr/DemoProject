spring:
  redis:
    redisson:
      config: ${datablau.redisson.config.location}
  server:
    servlet:
      context-path: /graph
  autoconfigure:
    exclude: com.alibaba.boot.nacos.discovery.autoconfigure.NacosDiscoveryAutoConfiguration
  session:
    store-type: redis
  data:
    neo4j:
      password: ${datablau.neo4j.authentication.password}
      username: ${datablau.neo4j.authentication.username}
      uri: ${datablau.neo4j.uri}
      uris: ${datablau.neo4j.uris}
  cloud:
    config:
      enabled: false
  kafka:
    # docker http://192.168.2.202:8080
    bootstrap-servers: ${common.kafka.bootstrap-servers}
    producer:
      retries: 3
      acks: 1
      batch-size: 16384
      properties:
        sasl:
          mechanism: PLAIN
          jaas:
            config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${common.kafka.n}" password="${common.kafka.w}";
        security:
          protocol: SASL_PLAINTEXT
        mechanism: PLAIN
        jaas:
          config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${common.kafka.n}" password="${common.kafka.w}";
        linger:
          ms: 100
      buffer-memory: 33554432
      # key的序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # value的序列化类
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      # 生产者生成的所有数据的压缩类型，此配置接受标准压缩编解码器（'gzip'，'snappy'，'lz4'，'zstd'）
      # 默认为none
      compression-type: none
    consumer:
      group-id: datablau_graph
      enable-auto-commit: false
      auto-offset-reset: latest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        sasl:
          mechanism: PLAIN
          jaas:
            config: org.apache.kafka.common.security.plain.PlainLoginModule required username="${common.kafka.n}" password="${common.kafka.w}";
        security:
          protocol: SASL_PLAINTEXT
        spring:
          json:
            trusted:
              packages: "com.datablau.graph.data.data"
      max-poll-records: 5000
    listener:
      type: batch
      concurrency: 2
main:
  banner-mode: console
aop:
  proxy-target-class: true

server:
  port: ${datablau.server.port}
  address: 0.0.0.0
  servlet:
    context-path: /
  error:
    include-stacktrace: always

logging:
  file:
    path: logs
  level:
    com.netflix: WARN
    com.datablau: INFO
    org:
      springframework:
        boot:
          autoconfigure:
            security: WARN
  pattern:
    file: "[%d{dd/MM/yy HH:mm:ss:sss z}] %-5p [%t](%c{1.}:%L) - %m%n"

datablau:
  db:
    url: ${common.db.url}
    driver-class-name: ${common.db.driver-class-name}
    ip-address: ${common.db.ip-address}
    port: ${common.db.port}
    target: graph
    parameters: ${common.db.parameters}
    username: ${common.db.username}
    password: ${common.db.password}
    dialect: ${common.db.dialect}
    hibernate:
      hbm2ddl: update
    max-total: 50
    min-idle: 2
    max-wait-millis: 30000
  redis:
    #redis的地址，在redisson.yaml中引用了该属性
    address: ${common.redis.address}
  redisson:
    config:
      location: nacos-data-id:redisson.yaml
  server:
    port: ${spring.cloud.nacos.discovery.port} #读取bootstrap中设置的ip
    address: ${spring.cloud.nacos.discovery.ip} #读取bootstrap中设置的port
  service:
    port: ${spring.cloud.nacos.discovery.port}
    call-port: 8100
  neo4j:
    authentication:
      # neo4j密码
      password: ${common.neo4j.authentication.password}
      # neo4j用户名
      username: ${common.neo4j.authentication.username}
    # neo4j地址
    uri: ${common.neo4j.uri}
    uris: ${common.neo4j.uris:}
  transport:
    #是否使用httpInvoker，如果为false或者不存在，则采用rmi
    http: true
  web-instance:
    name: datablau-graph-web
    enable: true
